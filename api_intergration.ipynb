{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# WB\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "from requests.exceptions import ChunkedEncodingError, RequestException\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "tokens = {\n",
        "    \"–•–¢–° –í–∏–∂–Ω\": \"\",\n",
        "    \"–•–¢–° –†—É—Å\": \" \"\n",
        "}\n",
        "\n",
        "final_file_path = \"\"\n",
        "\n",
        "\n",
        "final_data = pd.read_excel(final_file_path)\n",
        "last_week = final_data[final_data[\"–ú–ü\"] == \"WB\"][\"–ù–µ–¥–µ–ª—è\"].max()\n",
        "if pd.isna(last_week):\n",
        "    last_week = 0\n",
        "print(f\"–ü–æ—Å–ª–µ–¥–Ω—è—è –Ω–µ–¥–µ–ª—è WB –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —Ñ–∞–π–ª–µ: {last_week}\")\n",
        "\n",
        "url = \"https://seller-analytics-api.wildberries.ru/api/v2/nm-report/detail\"\n",
        "\n",
        "\n",
        "def get_page(page_number, start_date, end_date, headers, retries=3):\n",
        "    payload = {\n",
        "        \"page\": page_number,\n",
        "        \"period\": {\n",
        "            \"begin\": start_date,\n",
        "            \"end\": end_date\n",
        "        },\n",
        "        \"limit\": 500\n",
        "    }\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = requests.post(url, headers=headers, json=payload, timeout=60)\n",
        "            response.raise_for_status()\n",
        "            return response.json().get(\"data\", {}).get(\"cards\", [])\n",
        "        except (ChunkedEncodingError, RequestException) as e:\n",
        "            print(f\"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retries} ‚Äî –æ—à–∏–±–∫–∞: {e}. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 60 —Å–µ–∫.\")\n",
        "            time.sleep(60)\n",
        "    return []\n",
        "\n",
        "\n",
        "def collect_data(start_date, end_date, headers):\n",
        "    all_data = []\n",
        "    page = 1\n",
        "    while True:\n",
        "        data = get_page(page, start_date, end_date, headers)\n",
        "        if not data:\n",
        "            break\n",
        "        all_data.extend(data)\n",
        "        if len(data) < 500:\n",
        "            break\n",
        "        page += 1\n",
        "        time.sleep(1)\n",
        "    return all_data\n",
        "\n",
        "\n",
        "today = datetime.today()\n",
        "prev_week = today.isocalendar()[1] - 1\n",
        "prev_week_year = today.isocalendar()[0]\n",
        "monday_last_week = datetime.strptime(f'{prev_week_year}-W{prev_week:02}-1', \"%G-W%V-%u\")\n",
        "date_list = [monday_last_week + timedelta(days=i) for i in range(7)]\n",
        "\n",
        "\n",
        "data_frames = []\n",
        "\n",
        "for company, token in tokens.items():\n",
        "    print(f\"\\n –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è: {company}\")\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": token\n",
        "    }\n",
        "\n",
        "    for single_date in tqdm(date_list, desc=f\"–ó–∞–≥—Ä—É–∑–∫–∞ {company}\"):\n",
        "        begin = single_date.replace(hour=0, minute=0, second=0).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        end = single_date.replace(hour=23, minute=59, second=59).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        data = collect_data(begin, end, headers)\n",
        "        if data:\n",
        "            df = pd.json_normalize(data)\n",
        "            df.rename(columns={\n",
        "                \"statistics.selectedPeriod.begin\": \"–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞\",\n",
        "                \"statistics.selectedPeriod.end\": \"–î–∞—Ç–∞ –∫–æ–Ω—Ü–∞\",\n",
        "                \"statistics.selectedPeriod.ordersCount\": \"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤\",\n",
        "                \"statistics.selectedPeriod.ordersSumRub\": \"–°—É–º–º–∞ –∑–∞–∫–∞–∑–æ–≤\",\n",
        "                \"statistics.selectedPeriod.buyoutsCount\": \"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∫—É–ø–æ–≤\",\n",
        "                \"statistics.selectedPeriod.buyoutsSumRub\": \"–°—É–º–º–∞ –≤—ã–∫—É–ø–æ–≤\",\n",
        "                \"stocks.stocksMp\": \"–û—Å—Ç–∞—Ç–∫–∏ MP\",\n",
        "                \"stocks.stocksWb\": \"–û—Å—Ç–∞—Ç–∫–∏ Wb\",\n",
        "                \"nmID\": \"ID\",\n",
        "                \"vendorCode\": \"–ê—Ä—Ç–∏–∫—É–ª\",\n",
        "                \"brandName\": \"–ë—Ä–µ–Ω–¥\",\n",
        "                \"object.name\": \"–ù–∞–∑–≤–∞–Ω–∏–µ\"\n",
        "            }, inplace=True)\n",
        "\n",
        "            df = df[[\n",
        "                \"–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞\", \"–î–∞—Ç–∞ –∫–æ–Ω—Ü–∞\", \"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤\", \"–°—É–º–º–∞ –∑–∞–∫–∞–∑–æ–≤\",\n",
        "                \"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∫—É–ø–æ–≤\", \"–°—É–º–º–∞ –≤—ã–∫—É–ø–æ–≤\", \"–û—Å—Ç–∞—Ç–∫–∏ MP\", \"–û—Å—Ç–∞—Ç–∫–∏ Wb\",\n",
        "                \"ID\", \"–ê—Ä—Ç–∏–∫—É–ª\", \"–ë—Ä–µ–Ω–¥\", \"–ù–∞–∑–≤–∞–Ω–∏–µ\"\n",
        "            ]]\n",
        "            df[\"–Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ\"] = company\n",
        "            df[\"–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏\"] = pd.to_datetime(df[\"–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞\"])\n",
        "            df[\"–ù–µ–¥–µ–ª—è\"] = df[\"–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏\"].apply(lambda x: x.isocalendar()[1])\n",
        "            df[\"–ú–ü\"] = \"WB\"\n",
        "            df = df[df[\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤\"] > 0]\n",
        "            data_frames.append(df)\n",
        "\n",
        "\n",
        "if data_frames:\n",
        "    full_df = pd.concat(data_frames, ignore_index=True)\n",
        "    full_df = full_df[full_df[\"–ù–µ–¥–µ–ª—è\"] > last_week]\n",
        "\n",
        "    final_block = full_df.rename(columns={\n",
        "        '–°—É–º–º–∞ –≤—ã–∫—É–ø–æ–≤': '–ü—Ä–æ–¥–∞–Ω–æ, —Ä—É–±.',\n",
        "        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∫—É–ø–æ–≤': '–ü—Ä–æ–¥–∞–Ω–æ, —à—Ç.'\n",
        "    })[['–Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ', '–ú–ü', '–ù–µ–¥–µ–ª—è', '–ê—Ä—Ç–∏–∫—É–ª', '–ë—Ä–µ–Ω–¥', '–ü—Ä–æ–¥–∞–Ω–æ, —Ä—É–±.', '–ü—Ä–æ–¥–∞–Ω–æ, —à—Ç.', '–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏']]\n",
        "\n",
        "    final_data = pd.concat([final_data, final_block], ignore_index=True)\n",
        "    final_data.drop_duplicates(inplace=True)\n",
        "\n",
        "    try:\n",
        "        with pd.ExcelWriter(final_file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
        "            final_data.to_excel(writer, index=False)\n",
        "        print(f\"\\n –î–∞–Ω–Ω—ã–µ WB —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ —Ñ–∞–π–ª: {final_file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\" –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}\")\n",
        "else:\n",
        "    print(\"–ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5myLWNlJYVE",
        "outputId": "85ac2e56-fbf9-41cf-9471-b5542b207804",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ü–æ—Å–ª–µ–¥–Ω—è—è –Ω–µ–¥–µ–ª—è WB –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —Ñ–∞–π–ª–µ: 13\n",
            "\n",
            "üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è: –•–¢–° –í–∏–∂–Ω\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r–ó–∞–≥—Ä—É–∑–∫–∞ –•–¢–° –í–∏–∂–Ω:   0%|          | 0/7 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ü–æ–ø—ã—Ç–∫–∞ 1/3 ‚Äî –æ—à–∏–±–∫–∞: 429 Client Error: Too Many Requests for url: https://seller-analytics-api.wildberries.ru/api/v2/nm-report/detail. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 60 —Å–µ–∫.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-c845db881ebb>:106: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"–Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ\"] = company\n",
            "<ipython-input-2-c845db881ebb>:107: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏\"] = pd.to_datetime(df[\"–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞\"])\n",
            "<ipython-input-2-c845db881ebb>:108: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"–ù–µ–¥–µ–ª—è\"] = df[\"–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏\"].apply(lambda x: x.isocalendar()[1])\n",
            "<ipython-input-2-c845db881ebb>:109: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"–ú–ü\"] = \"WB\"\n",
            "\r–ó–∞–≥—Ä—É–∑–∫–∞ –•–¢–° –í–∏–∂–Ω:  14%|‚ñà‚ñç        | 1/7 [01:14<07:28, 74.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ü–æ–ø—ã—Ç–∫–∞ 1/3 ‚Äî –æ—à–∏–±–∫–∞: 429 Client Error: Too Many Requests for url: https://seller-analytics-api.wildberries.ru/api/v2/nm-report/detail. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 60 —Å–µ–∫.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r–ó–∞–≥—Ä—É–∑–∫–∞ –•–¢–° –í–∏–∂–Ω:  29%|‚ñà‚ñà‚ñä       | 2/7 [02:28<06:09, 73.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ü–æ–ø—ã—Ç–∫–∞ 1/3 ‚Äî –æ—à–∏–±–∫–∞: 429 Client Error: Too Many Requests for url: https://seller-analytics-api.wildberries.ru/api/v2/nm-report/detail. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 60 —Å–µ–∫.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r–ó–∞–≥—Ä—É–∑–∫–∞ –•–¢–° –í–∏–∂–Ω:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [03:42<04:56, 74.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ü–æ–ø—ã—Ç–∫–∞ 1/3 ‚Äî –æ—à–∏–±–∫–∞: 429 Client Error: Too Many Requests for url: https://seller-analytics-api.wildberries.ru/api/v2/nm-report/detail. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 60 —Å–µ–∫.\n",
            "–ü–æ–ø—ã—Ç–∫–∞ 1/3 ‚Äî –æ—à–∏–±–∫–∞: 429 Client Error: Too Many Requests for url: https://seller-analytics-api.wildberries.ru/api/v2/nm-report/detail. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 60 —Å–µ–∫.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r–ó–∞–≥—Ä—É–∑–∫–∞ –•–¢–° –í–∏–∂–Ω:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [06:00<04:57, 99.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ü–æ–ø—ã—Ç–∫–∞ 1/3 ‚Äî –æ—à–∏–±–∫–∞: 429 Client Error: Too Many Requests for url: https://seller-analytics-api.wildberries.ru/api/v2/nm-report/detail. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 60 —Å–µ–∫.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r–ó–∞–≥—Ä—É–∑–∫–∞ –•–¢–° –í–∏–∂–Ω:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [07:22<03:06, 93.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ü–æ–ø—ã—Ç–∫–∞ 1/3 ‚Äî –æ—à–∏–±–∫–∞: 429 Client Error: Too Many Requests for url: https://seller-analytics-api.wildberries.ru/api/v2/nm-report/detail. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 60 —Å–µ–∫.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r–ó–∞–≥—Ä—É–∑–∫–∞ –•–¢–° –í–∏–∂–Ω:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [08:40<01:28, 88.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ü–æ–ø—ã—Ç–∫–∞ 1/3 ‚Äî –æ—à–∏–±–∫–∞: 429 Client Error: Too Many Requests for url: https://seller-analytics-api.wildberries.ru/api/v2/nm-report/detail. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 60 —Å–µ–∫.\n",
            "–ü–æ–ø—ã—Ç–∫–∞ 1/3 ‚Äî –æ—à–∏–±–∫–∞: 429 Client Error: Too Many Requests for url: https://seller-analytics-api.wildberries.ru/api/v2/nm-report/detail. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 60 —Å–µ–∫.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "–ó–∞–≥—Ä—É–∑–∫–∞ –•–¢–° –í–∏–∂–Ω: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [10:56<00:00, 93.72s/it] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è: –•–¢–° –†—É—Å\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "–ó–∞–≥—Ä—É–∑–∫–∞ –•–¢–° –†—É—Å:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:09<00:11,  2.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ü–æ–ø—ã—Ç–∫–∞ 1/3 ‚Äî –æ—à–∏–±–∫–∞: 429 Client Error: Too Many Requests for url: https://seller-analytics-api.wildberries.ru/api/v2/nm-report/detail. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 60 —Å–µ–∫.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "–ó–∞–≥—Ä—É–∑–∫–∞ –•–¢–° –†—É—Å:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [01:11<01:19, 26.54s/it]<ipython-input-2-c845db881ebb>:106: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"–Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ\"] = company\n",
            "<ipython-input-2-c845db881ebb>:107: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏\"] = pd.to_datetime(df[\"–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞\"])\n",
            "<ipython-input-2-c845db881ebb>:108: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"–ù–µ–¥–µ–ª—è\"] = df[\"–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏\"].apply(lambda x: x.isocalendar()[1])\n",
            "<ipython-input-2-c845db881ebb>:109: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"–ú–ü\"] = \"WB\"\n",
            "–ó–∞–≥—Ä—É–∑–∫–∞ –•–¢–° –†—É—Å:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [01:22<00:13, 13.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ü–æ–ø—ã—Ç–∫–∞ 1/3 ‚Äî –æ—à–∏–±–∫–∞: 429 Client Error: Too Many Requests for url: https://seller-analytics-api.wildberries.ru/api/v2/nm-report/detail. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 60 —Å–µ–∫.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "–ó–∞–≥—Ä—É–∑–∫–∞ –•–¢–° –†—É—Å: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [02:35<00:00, 22.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " –î–∞–Ω–Ω—ã–µ WB —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ —Ñ–∞–π–ª: /content/–ü—Ä–æ–¥–∞–∂–∏_—Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª 2025.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\")\n",
        "\n",
        "final_file_path = \"/content/–ü—Ä–æ–¥–∞–∂–∏_—Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª 2025.xlsx\"\n",
        "reference_file_path = \"/content/–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫_Ozon.xlsx\"\n",
        "\n",
        "entities = {\n",
        "    \"–•–¢–° –í–∏–∂–Ω\": {\n",
        "        \"api_key\": \"\",\n",
        "        \"businessId\":\n",
        "    },\n",
        "    \"–•–¢–° –†—É—Å\": {\n",
        "        \"api_key\": \"\",\n",
        "        \"businessId\":\n",
        "    }\n",
        "}\n",
        "\n",
        "today = datetime.today()\n",
        "prev_week = today.isocalendar()[1] - 1\n",
        "prev_year = today.isocalendar()[0]\n",
        "monday = datetime.strptime(f\"{prev_year}-W{prev_week}-1\", \"%G-W%V-%u\")\n",
        "sunday = monday + timedelta(days=6)\n",
        "date_from_str = monday.strftime(\"%Y-%m-%d\")\n",
        "date_to_str = sunday.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "print(f\"–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–µ—Ä–∏–æ–¥: {date_from_str} ‚Äî {date_to_str}\")\n",
        "\n",
        "\n",
        "final_data = pd.read_excel(final_file_path)\n",
        "last_week = final_data[final_data['–ú–ü'] == 'YM']['–ù–µ–¥–µ–ª—è'].max()\n",
        "if pd.isna(last_week):\n",
        "    last_week = 0\n",
        "\n",
        "reference_df = pd.read_excel(reference_file_path)\n",
        "reference_df.rename(columns={'–ê—Ä—Ç–∏–∫—É–ª': '–í–∞—à SKU', '–ë—Ä–µ–Ω–¥': '–ë—Ä–µ–Ω–¥_HTS'}, inplace=True)\n",
        "\n",
        "\n",
        "def generate_and_download_report(api_key, business_id):\n",
        "    url_generate = \"https://api.partner.market.yandex.ru/reports/shows-sales/generate\"\n",
        "    headers = {\"Content-Type\": \"application/json\", \"Api-Key\": api_key}\n",
        "    body = {\n",
        "        \"businessId\": business_id,\n",
        "        \"dateFrom\": date_from_str,\n",
        "        \"dateTo\": date_to_str,\n",
        "        \"grouping\": \"OFFERS\"\n",
        "    }\n",
        "\n",
        "    response = requests.post(url_generate, json=body, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "    report_id = response.json()[\"result\"][\"reportId\"]\n",
        "    url_info = f\"https://api.partner.market.yandex.ru/reports/info/{report_id}\"\n",
        "\n",
        "    for attempt in range(10):\n",
        "        resp = requests.get(url_info, headers=headers)\n",
        "        if resp.status_code == 200 and resp.json()[\"result\"][\"status\"] == \"DONE\":\n",
        "            return resp.json()[\"result\"][\"file\"]\n",
        "        elif resp.json()[\"result\"][\"status\"] == \"ERROR\":\n",
        "            print(\"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞\")\n",
        "            return None\n",
        "        time.sleep(10)\n",
        "    print(\"–¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –æ—Ç—á–µ—Ç–∞.\")\n",
        "    return None\n",
        "\n",
        "def process_report(file_url, legal_entity):\n",
        "    response = requests.get(file_url, stream=True)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –æ—Ç—á–µ—Ç–∞: {response.status_code}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    df = pd.read_excel(file_url)\n",
        "    df[\"–Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ\"] = legal_entity\n",
        "    df[\"–ú–ü\"] = \"YM\"\n",
        "    df[\"–ù–µ–¥–µ–ª—è\"] = monday.isocalendar()[1]\n",
        "    df.rename(columns={\"–î–µ–Ω—å\": \"–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏\"}, inplace=True)\n",
        "\n",
        "\n",
        "    df = df.merge(reference_df[['–í–∞—à SKU', '–ë—Ä–µ–Ω–¥_HTS']], on='–í–∞—à SKU', how='left')\n",
        "\n",
        "    df = df.rename(columns={\n",
        "        '–í–∞—à SKU': '–ê—Ä—Ç–∏–∫—É–ª',\n",
        "        '–ë—Ä–µ–Ω–¥_HTS': '–ë—Ä–µ–Ω–¥',\n",
        "        '–î–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –∑–∞ –ø–µ—Ä–∏–æ–¥ –Ω–∞ —Å—É–º–º—É, ‚ÇΩ': '–ü—Ä–æ–¥–∞–Ω–æ, —Ä—É–±.',\n",
        "        '–î–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –∑–∞ –ø–µ—Ä–∏–æ–¥, —à—Ç.': '–ü—Ä–æ–¥–∞–Ω–æ, —à—Ç.'\n",
        "    })[['–Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ', '–ú–ü', '–ù–µ–¥–µ–ª—è', '–ê—Ä—Ç–∏–∫—É–ª', '–ë—Ä–µ–Ω–¥', '–ü—Ä–æ–¥–∞–Ω–æ, —Ä—É–±.', '–ü—Ä–æ–¥–∞–Ω–æ, —à—Ç.', '–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏']]\n",
        "\n",
        "    df['–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏'] = pd.to_datetime(df['–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏'], errors='coerce').dt.strftime('%d.%m.%Y %H:%M:%S')\n",
        "    df = df.dropna(subset=['–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏'])\n",
        "\n",
        "    return df\n",
        "\n",
        "all_data = pd.DataFrame()\n",
        "for entity_name, creds in entities.items():\n",
        "    print(f\"\\n –û–±—Ä–∞–±–æ—Ç–∫–∞: {entity_name}\")\n",
        "    file_url = generate_and_download_report(creds['api_key'], creds['businessId'])\n",
        "    if file_url:\n",
        "        df = process_report(file_url, entity_name)\n",
        "        all_data = pd.concat([all_data, df], ignore_index=True)\n",
        "\n",
        "\n",
        "if not all_data.empty:\n",
        "    all_data = all_data.loc[:, ~all_data.columns.duplicated()]\n",
        "    all_data = all_data[all_data[\"–ù–µ–¥–µ–ª—è\"] > last_week]\n",
        "\n",
        "    missing_cols = [col for col in final_data.columns if col not in all_data.columns]\n",
        "    for col in missing_cols:\n",
        "        all_data[col] = None\n",
        "\n",
        "    all_data = all_data[final_data.columns]  # –ü–µ—Ä–µ—Å—Ç–∞–≤–∏–º –ø–æ—Ä—è–¥–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤\n",
        "    final_data = pd.concat([final_data, all_data], ignore_index=True)\n",
        "    final_data.drop_duplicates(inplace=True)\n",
        "\n",
        "    try:\n",
        "        with pd.ExcelWriter(final_file_path, engine=\"openpyxl\", mode='a', if_sheet_exists='replace') as writer:\n",
        "            final_data.to_excel(writer, index=False)\n",
        "        print(f\"\\n –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ —Ñ–∞–π–ª: {final_file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}\")\n",
        "else:\n",
        "    print(\"–ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNFmWrzjKmbz",
        "outputId": "da984300-bf84-42b9-e990-de68ab7cfb65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–µ—Ä–∏–æ–¥: 2025-03-31 ‚Äî 2025-04-06\n",
            "\n",
            "üì• –û–±—Ä–∞–±–æ—Ç–∫–∞: –•–¢–° –í–∏–∂–Ω\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-1ce21deccd73>:98: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  df['–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏'] = pd.to_datetime(df['–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏'], errors='coerce').dt.strftime('%d.%m.%Y %H:%M:%S')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì• –û–±—Ä–∞–±–æ—Ç–∫–∞: –•–¢–° –†—É—Å\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-1ce21deccd73>:98: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  df['–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏'] = pd.to_datetime(df['–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏'], errors='coerce').dt.strftime('%d.%m.%Y %H:%M:%S')\n",
            "<ipython-input-7-1ce21deccd73>:123: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  final_data = pd.concat([final_data, all_data], ignore_index=True)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}